{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e03bf51",
   "metadata": {},
   "source": [
    "Encoder Decoder stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680bc5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3354014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c6bdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tekju\\Desktop\\nlp_scratch\\nlp_env\\Lib\\site-packages\\torchtext\\datasets\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "c:\\Users\\tekju\\Desktop\\nlp_scratch\\nlp_env\\Lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83f7059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module,N):\n",
    "    \"produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58172586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module.\"\n",
    "    def __init__(self,features,eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(-1,keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x-mean) / (std+self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9c6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNorm(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab7895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221b9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"A residual connection followed by a layer norm.\"\n",
    "    def __init__(self,size,dropout):\n",
    "        super(SublayerConnection,self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x,sublayer):\n",
    "        \"apply residual conn to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x))) # pre-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d116a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05226b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"self-attn and feedforward\"\n",
    "    def __init__(self,size, self_attn, feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size,dropout),2)\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x,x,x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055ec66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfbc8d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,size,self_attn,src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.size= size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout),3)\n",
    "        \n",
    "    def forward(self,x,memory,src_mask,tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x,x,x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x,m,m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc71898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5697e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"core encoder is a stack of N layers.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.layers = clones(layer,N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self,x,mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479e005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f09dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,layer,N):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.layers = clones(layer,N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self,x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x,memory,src_mask,tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a515e",
   "metadata": {},
   "source": [
    "Attention and Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f1331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"mask out subsequent positions.\"\n",
    "    attn_shape = (1,size,size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape),diagonal=1).type(\n",
    "    torch.uint8\n",
    "    )\n",
    "    return subsequent_mask==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4946d32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True, False, False],\n",
       "         [ True,  True, False],\n",
       "         [ True,  True,  True]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = subsequent_mask(3)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58238e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"compute scaled dot product attention\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn,value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591358b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27d68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,h,d_model,dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model//h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model,d_model),4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self,query,key,value,mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # do all linear proj in batch from d_model => h * d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h,self.d_k).transpose(1,2)\n",
    "            for lin, x in zip(self.linears, (query,key,value))\n",
    "        ]\n",
    "\n",
    "        # apply attention on all projected vectors in batch.\n",
    "        x, self.attn = attention(\n",
    "            query,key,value,mask=mask,dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # concat using view and apply final linear.\n",
    "        x = (\n",
    "            x.transpose(1,2)\n",
    "            .contiguous()\n",
    "            .view(nbatches,-1,self.h*self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9b1eb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 8, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4,3,512).view(4,-1,8,64).shape # into heads per seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7cce309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 3, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4,3,512).view(4,-1,8,64).transpose(1,2).shape # into seqs per head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cc708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed950d9",
   "metadata": {},
   "source": [
    "FFN and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd356fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "        super(PositionwiseFeedForward,self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model,d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff,d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1c0e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = PositionwiseFeedForward(512,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fce0c803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0118, -0.0520,  0.0460,  ...,  0.0097,  0.2788, -0.1766],\n",
       "         [ 0.0502,  0.0106, -0.0035,  ..., -0.0663,  0.1567, -0.1496],\n",
       "         [ 0.0162, -0.0596,  0.1255,  ..., -0.0254,  0.1744,  0.0534],\n",
       "         [ 0.1888, -0.1108,  0.0816,  ...,  0.1911,  0.2350, -0.1343]],\n",
       "\n",
       "        [[ 0.0274, -0.0031, -0.0575,  ...,  0.0848,  0.1802, -0.1993],\n",
       "         [ 0.0591,  0.0117,  0.2198,  ..., -0.0434,  0.0128, -0.1241],\n",
       "         [ 0.0835, -0.0556,  0.1465,  ...,  0.1510,  0.1317, -0.1677],\n",
       "         [-0.0018, -0.0270, -0.0737,  ...,  0.0573,  0.0062, -0.1245]],\n",
       "\n",
       "        [[-0.0258, -0.0746,  0.1187,  ..., -0.0866,  0.1113, -0.2158],\n",
       "         [ 0.1626, -0.0341,  0.0792,  ...,  0.0794,  0.1311, -0.1301],\n",
       "         [ 0.2096, -0.2094,  0.0165,  ..., -0.0553,  0.1145, -0.1533],\n",
       "         [ 0.1490, -0.0736,  0.0971,  ..., -0.0034,  0.0821, -0.1988]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn(torch.rand(3,4,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a985d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model,vocab):\n",
    "        super(Embeddings,self).__init__()\n",
    "        self.lut = nn.Embedding(vocab,d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a54b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model,dropout,max_len=5000):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # compute the positional encodings once in log space\n",
    "        pe = torch.zeros(max_len,d_model)\n",
    "        position = torch.arange(0,max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0,d_model,2) * -(math.log(10000.0)/d_model)\n",
    "        )\n",
    "        pe[:,0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\",pe)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x + self.pe[:,: x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34573277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bc29bb03eae14380a70b458a187fe8d3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bc29bb03eae14380a70b458a187fe8d3.vega-embed details,\n",
       "  #altair-viz-bc29bb03eae14380a70b458a187fe8d3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bc29bb03eae14380a70b458a187fe8d3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bc29bb03eae14380a70b458a187fe8d3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bc29bb03eae14380a70b458a187fe8d3\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@6?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@6.1.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@7?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"6\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"6.1.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"7\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-74197a450f4fae82b525a303f60629a7\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"dimension\", \"type\": \"nominal\"}, \"x\": {\"field\": \"position\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"embedding\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_1e9efca18e7a2868\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v6.1.0.json\", \"datasets\": {\"data-74197a450f4fae82b525a303f60629a7\": [{\"embedding\": 0.0, \"dimension\": 4, \"position\": 0}, {\"embedding\": 0.15782663226127625, \"dimension\": 4, \"position\": 1}, {\"embedding\": 0.3116971552371979, \"dimension\": 4, \"position\": 2}, {\"embedding\": 0.45775455236434937, \"dimension\": 4, \"position\": 3}, {\"embedding\": 0.5923377275466919, \"dimension\": 4, \"position\": 4}, {\"embedding\": 0.7120732069015503, \"dimension\": 4, \"position\": 5}, {\"embedding\": 0.813959538936615, \"dimension\": 4, \"position\": 6}, {\"embedding\": 0.8954429626464844, \"dimension\": 4, \"position\": 7}, {\"embedding\": 0.9544808864593506, \"dimension\": 4, \"position\": 8}, {\"embedding\": 0.989593505859375, \"dimension\": 4, \"position\": 9}, {\"embedding\": 0.9999006390571594, \"dimension\": 4, \"position\": 10}, {\"embedding\": 0.9851439595222473, \"dimension\": 4, \"position\": 11}, {\"embedding\": 0.94569331407547, \"dimension\": 4, \"position\": 12}, {\"embedding\": 0.8825376033782959, \"dimension\": 4, \"position\": 13}, {\"embedding\": 0.7972599267959595, \"dimension\": 4, \"position\": 14}, {\"embedding\": 0.6919978260993958, \"dimension\": 4, \"position\": 15}, {\"embedding\": 0.5693899393081665, \"dimension\": 4, \"position\": 16}, {\"embedding\": 0.4325096309185028, \"dimension\": 4, \"position\": 17}, {\"embedding\": 0.284787654876709, \"dimension\": 4, \"position\": 18}, {\"embedding\": 0.12992730736732483, \"dimension\": 4, \"position\": 19}, {\"embedding\": -0.028190065175294876, \"dimension\": 4, \"position\": 20}, {\"embedding\": -0.18560057878494263, \"dimension\": 4, \"position\": 21}, {\"embedding\": -0.3383587896823883, \"dimension\": 4, \"position\": 22}, {\"embedding\": -0.4826357960700989, \"dimension\": 4, \"position\": 23}, {\"embedding\": -0.6148146390914917, \"dimension\": 4, \"position\": 24}, {\"embedding\": -0.7315824031829834, \"dimension\": 4, \"position\": 25}, {\"embedding\": -0.8300122618675232, \"dimension\": 4, \"position\": 26}, {\"embedding\": -0.9076365828514099, \"dimension\": 4, \"position\": 27}, {\"embedding\": -0.96250981092453, \"dimension\": 4, \"position\": 28}, {\"embedding\": -0.9932565093040466, \"dimension\": 4, \"position\": 29}, {\"embedding\": -0.9991058707237244, \"dimension\": 4, \"position\": 30}, {\"embedding\": -0.9799113273620605, \"dimension\": 4, \"position\": 31}, {\"embedding\": -0.9361540079116821, \"dimension\": 4, \"position\": 32}, {\"embedding\": -0.8689308166503906, \"dimension\": 4, \"position\": 33}, {\"embedding\": -0.7799267172813416, \"dimension\": 4, \"position\": 34}, {\"embedding\": -0.6713724136352539, \"dimension\": 4, \"position\": 35}, {\"embedding\": -0.5459895133972168, \"dimension\": 4, \"position\": 36}, {\"embedding\": -0.40692076086997986, \"dimension\": 4, \"position\": 37}, {\"embedding\": -0.2576519548892975, \"dimension\": 4, \"position\": 38}, {\"embedding\": -0.10192479938268661, \"dimension\": 4, \"position\": 39}, {\"embedding\": 0.056357722729444504, \"dimension\": 4, \"position\": 40}, {\"embedding\": 0.21322709321975708, \"dimension\": 4, \"position\": 41}, {\"embedding\": 0.3647516369819641, \"dimension\": 4, \"position\": 42}, {\"embedding\": 0.5071332454681396, \"dimension\": 4, \"position\": 43}, {\"embedding\": 0.6368028521537781, \"dimension\": 4, \"position\": 44}, {\"embedding\": 0.7505101561546326, \"dimension\": 4, \"position\": 45}, {\"embedding\": 0.8454052805900574, \"dimension\": 4, \"position\": 46}, {\"embedding\": 0.9191088080406189, \"dimension\": 4, \"position\": 47}, {\"embedding\": 0.9697737693786621, \"dimension\": 4, \"position\": 48}, {\"embedding\": 0.9961300492286682, \"dimension\": 4, \"position\": 49}, {\"embedding\": 0.9975170493125916, \"dimension\": 4, \"position\": 50}, {\"embedding\": 0.9738998413085938, \"dimension\": 4, \"position\": 51}, {\"embedding\": 0.9258706569671631, \"dimension\": 4, \"position\": 52}, {\"embedding\": 0.8546332716941833, \"dimension\": 4, \"position\": 53}, {\"embedding\": 0.7619734406471252, \"dimension\": 4, \"position\": 54}, {\"embedding\": 0.6502137184143066, \"dimension\": 4, \"position\": 55}, {\"embedding\": 0.5221555233001709, \"dimension\": 4, \"position\": 56}, {\"embedding\": 0.38100889325141907, \"dimension\": 4, \"position\": 57}, {\"embedding\": 0.23031172156333923, \"dimension\": 4, \"position\": 58}, {\"embedding\": 0.07384055852890015, \"dimension\": 4, \"position\": 59}, {\"embedding\": -0.08448058366775513, \"dimension\": 4, \"position\": 60}, {\"embedding\": -0.2406841218471527, \"dimension\": 4, \"position\": 61}, {\"embedding\": -0.3908545970916748, \"dimension\": 4, \"position\": 62}, {\"embedding\": -0.5312277674674988, \"dimension\": 4, \"position\": 63}, {\"embedding\": -0.6582850813865662, \"dimension\": 4, \"position\": 64}, {\"embedding\": -0.768841564655304, \"dimension\": 4, \"position\": 65}, {\"embedding\": -0.8601260781288147, \"dimension\": 4, \"position\": 66}, {\"embedding\": -0.9298503994941711, \"dimension\": 4, \"position\": 67}, {\"embedding\": -0.9762668013572693, \"dimension\": 4, \"position\": 68}, {\"embedding\": -0.9982118010520935, \"dimension\": 4, \"position\": 69}, {\"embedding\": -0.9951352477073669, \"dimension\": 4, \"position\": 70}, {\"embedding\": -0.967114269733429, \"dimension\": 4, \"position\": 71}, {\"embedding\": -0.9148513078689575, \"dimension\": 4, \"position\": 72}, {\"embedding\": -0.839656412601471, \"dimension\": 4, \"position\": 73}, {\"embedding\": -0.7434144616127014, \"dimension\": 4, \"position\": 74}, {\"embedding\": -0.6285378336906433, \"dimension\": 4, \"position\": 75}, {\"embedding\": -0.4979061186313629, \"dimension\": 4, \"position\": 76}, {\"embedding\": -0.3547937273979187, \"dimension\": 4, \"position\": 77}, {\"embedding\": -0.20278796553611755, \"dimension\": 4, \"position\": 78}, {\"embedding\": -0.04569905996322632, \"dimension\": 4, \"position\": 79}, {\"embedding\": 0.11253630369901657, \"dimension\": 4, \"position\": 80}, {\"embedding\": 0.2679498493671417, \"dimension\": 4, \"position\": 81}, {\"embedding\": 0.4166468679904938, \"dimension\": 4, \"position\": 82}, {\"embedding\": 0.5549001097679138, \"dimension\": 4, \"position\": 83}, {\"embedding\": 0.6792440414428711, \"dimension\": 4, \"position\": 84}, {\"embedding\": 0.7865618467330933, \"dimension\": 4, \"position\": 85}, {\"embedding\": 0.8741634488105774, \"dimension\": 4, \"position\": 86}, {\"embedding\": 0.9398530125617981, \"dimension\": 4, \"position\": 87}, {\"embedding\": 0.9819839596748352, \"dimension\": 4, \"position\": 88}, {\"embedding\": 0.9995002150535583, \"dimension\": 4, \"position\": 89}, {\"embedding\": 0.9919626712799072, \"dimension\": 4, \"position\": 90}, {\"embedding\": 0.959559977054596, \"dimension\": 4, \"position\": 91}, {\"embedding\": 0.903104841709137, \"dimension\": 4, \"position\": 92}, {\"embedding\": 0.8240122199058533, \"dimension\": 4, \"position\": 93}, {\"embedding\": 0.7242646217346191, \"dimension\": 4, \"position\": 94}, {\"embedding\": 0.6063624024391174, \"dimension\": 4, \"position\": 95}, {\"embedding\": 0.4732609689235687, \"dimension\": 4, \"position\": 96}, {\"embedding\": 0.32829657196998596, \"dimension\": 4, \"position\": 97}, {\"embedding\": 0.17510302364826202, \"dimension\": 4, \"position\": 98}, {\"embedding\": 0.01752028614282608, \"dimension\": 4, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 5, \"position\": 0}, {\"embedding\": 0.9874668121337891, \"dimension\": 5, \"position\": 1}, {\"embedding\": 0.9501814842224121, \"dimension\": 5, \"position\": 2}, {\"embedding\": 0.8890786170959473, \"dimension\": 5, \"position\": 3}, {\"embedding\": 0.8056897521018982, \"dimension\": 5, \"position\": 4}, {\"embedding\": 0.7021052241325378, \"dimension\": 5, \"position\": 5}, {\"embedding\": 0.5809215903282166, \"dimension\": 5, \"position\": 6}, {\"embedding\": 0.44517630338668823, \"dimension\": 5, \"position\": 7}, {\"embedding\": 0.2982720732688904, \"dimension\": 5, \"position\": 8}, {\"embedding\": 0.14389123022556305, \"dimension\": 5, \"position\": 9}, {\"embedding\": -0.01409643329679966, \"dimension\": 5, \"position\": 10}, {\"embedding\": -0.1717306226491928, \"dimension\": 5, \"position\": 11}, {\"embedding\": -0.32506027817726135, \"dimension\": 5, \"position\": 12}, {\"embedding\": -0.47024187445640564, \"dimension\": 5, \"position\": 13}, {\"embedding\": -0.6036361455917358, \"dimension\": 5, \"position\": 14}, {\"embedding\": -0.7218996286392212, \"dimension\": 5, \"position\": 15}, {\"embedding\": -0.8220675587654114, \"dimension\": 5, \"position\": 16}, {\"embedding\": -0.9016293287277222, \"dimension\": 5, \"position\": 17}, {\"embedding\": -0.9585906267166138, \"dimension\": 5, \"position\": 18}, {\"embedding\": -0.9915235042572021, \"dimension\": 5, \"position\": 19}, {\"embedding\": -0.9996025562286377, \"dimension\": 5, \"position\": 20}, {\"embedding\": -0.9826252460479736, \"dimension\": 5, \"position\": 21}, {\"embedding\": -0.941017210483551, \"dimension\": 5, \"position\": 22}, {\"embedding\": -0.8758211731910706, \"dimension\": 5, \"position\": 23}, {\"embedding\": -0.788671612739563, \"dimension\": 5, \"position\": 24}, {\"embedding\": -0.6817529797554016, \"dimension\": 5, \"position\": 25}, {\"embedding\": -0.5577451586723328, \"dimension\": 5, \"position\": 26}, {\"embedding\": -0.4197568893432617, \"dimension\": 5, \"position\": 27}, {\"embedding\": -0.27124688029289246, \"dimension\": 5, \"position\": 28}, {\"embedding\": -0.11593768745660782, \"dimension\": 5, \"position\": 29}, {\"embedding\": 0.042278096079826355, \"dimension\": 5, \"position\": 30}, {\"embedding\": 0.19943365454673767, \"dimension\": 5, \"position\": 31}, {\"embedding\": 0.3515901565551758, \"dimension\": 5, \"position\": 32}, {\"embedding\": 0.4949335753917694, \"dimension\": 5, \"position\": 33}, {\"embedding\": 0.6258708238601685, \"dimension\": 5, \"position\": 34}, {\"embedding\": 0.7411201596260071, \"dimension\": 5, \"position\": 35}, {\"embedding\": 0.8377919793128967, \"dimension\": 5, \"position\": 36}, {\"embedding\": 0.9134634733200073, \"dimension\": 5, \"position\": 37}, {\"embedding\": 0.9662377834320068, \"dimension\": 5, \"position\": 38}, {\"embedding\": 0.994792103767395, \"dimension\": 5, \"position\": 39}, {\"embedding\": 0.9984106421470642, \"dimension\": 5, \"position\": 40}, {\"embedding\": 0.9770026803016663, \"dimension\": 5, \"position\": 41}, {\"embedding\": 0.931104838848114, \"dimension\": 5, \"position\": 42}, {\"embedding\": 0.8618676662445068, \"dimension\": 5, \"position\": 43}, {\"embedding\": 0.7710266709327698, \"dimension\": 5, \"position\": 44}, {\"embedding\": 0.6608588695526123, \"dimension\": 5, \"position\": 45}, {\"embedding\": 0.5341253876686096, \"dimension\": 5, \"position\": 46}, {\"embedding\": 0.3940037488937378, \"dimension\": 5, \"position\": 47}, {\"embedding\": 0.24400585889816284, \"dimension\": 5, \"position\": 48}, {\"embedding\": 0.08789165318012238, \"dimension\": 5, \"position\": 49}, {\"embedding\": -0.07042567431926727, \"dimension\": 5, \"position\": 50}, {\"embedding\": -0.2269781529903412, \"dimension\": 5, \"position\": 51}, {\"embedding\": -0.37784066796302795, \"dimension\": 5, \"position\": 52}, {\"embedding\": -0.5192320942878723, \"dimension\": 5, \"position\": 53}, {\"embedding\": -0.6476082801818848, \"dimension\": 5, \"position\": 54}, {\"embedding\": -0.7597513794898987, \"dimension\": 5, \"position\": 55}, {\"embedding\": -0.8528502583503723, \"dimension\": 5, \"position\": 56}, {\"embedding\": -0.9245713949203491, \"dimension\": 5, \"position\": 57}, {\"embedding\": -0.973116934299469, \"dimension\": 5, \"position\": 58}, {\"embedding\": -0.9972700476646423, \"dimension\": 5, \"position\": 59}, {\"embedding\": -0.9964250922203064, \"dimension\": 5, \"position\": 60}, {\"embedding\": -0.9706035256385803, \"dimension\": 5, \"position\": 61}, {\"embedding\": -0.9204524159431458, \"dimension\": 5, \"position\": 62}, {\"embedding\": -0.8472290635108948, \"dimension\": 5, \"position\": 63}, {\"embedding\": -0.7527687549591064, \"dimension\": 5, \"position\": 64}, {\"embedding\": -0.6394393444061279, \"dimension\": 5, \"position\": 65}, {\"embedding\": -0.5100815296173096, \"dimension\": 5, \"position\": 66}, {\"embedding\": -0.3679378628730774, \"dimension\": 5, \"position\": 67}, {\"embedding\": -0.2165713608264923, \"dimension\": 5, \"position\": 68}, {\"embedding\": -0.05977622792124748, \"dimension\": 5, \"position\": 69}, {\"embedding\": 0.09851823002099991, \"dimension\": 5, \"position\": 70}, {\"embedding\": 0.254342257976532, \"dimension\": 5, \"position\": 71}, {\"embedding\": 0.4037908613681793, \"dimension\": 5, \"position\": 72}, {\"embedding\": 0.543117880821228, \"dimension\": 5, \"position\": 73}, {\"embedding\": 0.6688309907913208, \"dimension\": 5, \"position\": 74}, {\"embedding\": 0.7777789831161499, \"dimension\": 5, \"position\": 75}, {\"embedding\": 0.8672309517860413, \"dimension\": 5, \"position\": 76}, {\"embedding\": 0.9349446296691895, \"dimension\": 5, \"position\": 77}, {\"embedding\": 0.9792226552963257, \"dimension\": 5, \"position\": 78}, {\"embedding\": 0.998955249786377, \"dimension\": 5, \"position\": 79}, {\"embedding\": 0.9936476349830627, \"dimension\": 5, \"position\": 80}, {\"embedding\": 0.9634328484535217, \"dimension\": 5, \"position\": 81}, {\"embedding\": 0.9090684056282043, \"dimension\": 5, \"position\": 82}, {\"embedding\": 0.8319169878959656, \"dimension\": 5, \"position\": 83}, {\"embedding\": 0.733912467956543, \"dimension\": 5, \"position\": 84}, {\"embedding\": 0.617511510848999, \"dimension\": 5, \"position\": 85}, {\"embedding\": 0.4856317937374115, \"dimension\": 5, \"position\": 86}, {\"embedding\": 0.3415791094303131, \"dimension\": 5, \"position\": 87}, {\"embedding\": 0.18896427750587463, \"dimension\": 5, \"position\": 88}, {\"embedding\": 0.0316128134727478, \"dimension\": 5, \"position\": 89}, {\"embedding\": -0.12653106451034546, \"dimension\": 5, \"position\": 90}, {\"embedding\": -0.28150418400764465, \"dimension\": 5, \"position\": 91}, {\"embedding\": -0.4294200837612152, \"dimension\": 5, \"position\": 92}, {\"embedding\": -0.5665720105171204, \"dimension\": 5, \"position\": 93}, {\"embedding\": -0.6895220875740051, \"dimension\": 5, \"position\": 94}, {\"embedding\": -0.7951884269714355, \"dimension\": 5, \"position\": 95}, {\"embedding\": -0.880922257900238, \"dimension\": 5, \"position\": 96}, {\"embedding\": -0.9445747137069702, \"dimension\": 5, \"position\": 97}, {\"embedding\": -0.9845501184463501, \"dimension\": 5, \"position\": 98}, {\"embedding\": -0.9998465180397034, \"dimension\": 5, \"position\": 99}, {\"embedding\": 0.0, \"dimension\": 6, \"position\": 0}, {\"embedding\": 0.06305388361215591, \"dimension\": 6, \"position\": 1}, {\"embedding\": 0.12585683166980743, \"dimension\": 6, \"position\": 2}, {\"embedding\": 0.18815888464450836, \"dimension\": 6, \"position\": 3}, {\"embedding\": 0.24971213936805725, \"dimension\": 6, \"position\": 4}, {\"embedding\": 0.31027159094810486, \"dimension\": 6, \"position\": 5}, {\"embedding\": 0.3695962131023407, \"dimension\": 6, \"position\": 6}, {\"embedding\": 0.4274499714374542, \"dimension\": 6, \"position\": 7}, {\"embedding\": 0.4836025834083557, \"dimension\": 6, \"position\": 8}, {\"embedding\": 0.5378305912017822, \"dimension\": 6, \"position\": 9}, {\"embedding\": 0.5899181365966797, \"dimension\": 6, \"position\": 10}, {\"embedding\": 0.6396579146385193, \"dimension\": 6, \"position\": 11}, {\"embedding\": 0.6868520379066467, \"dimension\": 6, \"position\": 12}, {\"embedding\": 0.7313126921653748, \"dimension\": 6, \"position\": 13}, {\"embedding\": 0.7728629112243652, \"dimension\": 6, \"position\": 14}, {\"embedding\": 0.8113372921943665, \"dimension\": 6, \"position\": 15}, {\"embedding\": 0.8465827703475952, \"dimension\": 6, \"position\": 16}, {\"embedding\": 0.8784590363502502, \"dimension\": 6, \"position\": 17}, {\"embedding\": 0.9068393111228943, \"dimension\": 6, \"position\": 18}, {\"embedding\": 0.9316105246543884, \"dimension\": 6, \"position\": 19}, {\"embedding\": 0.9526742100715637, \"dimension\": 6, \"position\": 20}, {\"embedding\": 0.9699464440345764, \"dimension\": 6, \"position\": 21}, {\"embedding\": 0.9833585619926453, \"dimension\": 6, \"position\": 22}, {\"embedding\": 0.9928570985794067, \"dimension\": 6, \"position\": 23}, {\"embedding\": 0.9984043836593628, \"dimension\": 6, \"position\": 24}, {\"embedding\": 0.999978244304657, \"dimension\": 6, \"position\": 25}, {\"embedding\": 0.9975724220275879, \"dimension\": 6, \"position\": 26}, {\"embedding\": 0.9911965131759644, \"dimension\": 6, \"position\": 27}, {\"embedding\": 0.9808759093284607, \"dimension\": 6, \"position\": 28}, {\"embedding\": 0.9666516780853271, \"dimension\": 6, \"position\": 29}, {\"embedding\": 0.9485803842544556, \"dimension\": 6, \"position\": 30}, {\"embedding\": 0.9267339110374451, \"dimension\": 6, \"position\": 31}, {\"embedding\": 0.9011994004249573, \"dimension\": 6, \"position\": 32}, {\"embedding\": 0.8720782399177551, \"dimension\": 6, \"position\": 33}, {\"embedding\": 0.8394865393638611, \"dimension\": 6, \"position\": 34}, {\"embedding\": 0.8035537600517273, \"dimension\": 6, \"position\": 35}, {\"embedding\": 0.7644230127334595, \"dimension\": 6, \"position\": 36}, {\"embedding\": 0.7222501039505005, \"dimension\": 6, \"position\": 37}, {\"embedding\": 0.6772029399871826, \"dimension\": 6, \"position\": 38}, {\"embedding\": 0.6294605135917664, \"dimension\": 6, \"position\": 39}, {\"embedding\": 0.57921302318573, \"dimension\": 6, \"position\": 40}, {\"embedding\": 0.5266605615615845, \"dimension\": 6, \"position\": 41}, {\"embedding\": 0.4720119535923004, \"dimension\": 6, \"position\": 42}, {\"embedding\": 0.41548484563827515, \"dimension\": 6, \"position\": 43}, {\"embedding\": 0.3573042154312134, \"dimension\": 6, \"position\": 44}, {\"embedding\": 0.29770180583000183, \"dimension\": 6, \"position\": 45}, {\"embedding\": 0.23691439628601074, \"dimension\": 6, \"position\": 46}, {\"embedding\": 0.17518411576747894, \"dimension\": 6, \"position\": 47}, {\"embedding\": 0.1127568930387497, \"dimension\": 6, \"position\": 48}, {\"embedding\": 0.04988069087266922, \"dimension\": 6, \"position\": 49}, {\"embedding\": -0.013194027356803417, \"dimension\": 6, \"position\": 50}, {\"embedding\": -0.07621623575687408, \"dimension\": 6, \"position\": 51}, {\"embedding\": -0.1389348804950714, \"dimension\": 6, \"position\": 52}, {\"embedding\": -0.20110084116458893, \"dimension\": 6, \"position\": 53}, {\"embedding\": -0.2624664604663849, \"dimension\": 6, \"position\": 54}, {\"embedding\": -0.3227875530719757, \"dimension\": 6, \"position\": 55}, {\"embedding\": -0.3818237781524658, \"dimension\": 6, \"position\": 56}, {\"embedding\": -0.4393406808376312, \"dimension\": 6, \"position\": 57}, {\"embedding\": -0.49510911107063293, \"dimension\": 6, \"position\": 58}, {\"embedding\": -0.5489069223403931, \"dimension\": 6, \"position\": 59}, {\"embedding\": -0.6005204319953918, \"dimension\": 6, \"position\": 60}, {\"embedding\": -0.6497439742088318, \"dimension\": 6, \"position\": 61}, {\"embedding\": -0.6963817477226257, \"dimension\": 6, \"position\": 62}, {\"embedding\": -0.7402478456497192, \"dimension\": 6, \"position\": 63}, {\"embedding\": -0.7811681628227234, \"dimension\": 6, \"position\": 64}, {\"embedding\": -0.8189795017242432, \"dimension\": 6, \"position\": 65}, {\"embedding\": -0.8535317182540894, \"dimension\": 6, \"position\": 66}, {\"embedding\": -0.8846868872642517, \"dimension\": 6, \"position\": 67}, {\"embedding\": -0.9123212099075317, \"dimension\": 6, \"position\": 68}, {\"embedding\": -0.936324954032898, \"dimension\": 6, \"position\": 69}, {\"embedding\": -0.956602156162262, \"dimension\": 6, \"position\": 70}, {\"embedding\": -0.9730724096298218, \"dimension\": 6, \"position\": 71}, {\"embedding\": -0.9856699705123901, \"dimension\": 6, \"position\": 72}, {\"embedding\": -0.9943448305130005, \"dimension\": 6, \"position\": 73}, {\"embedding\": -0.9990625381469727, \"dimension\": 6, \"position\": 74}, {\"embedding\": -0.9998041391372681, \"dimension\": 6, \"position\": 75}, {\"embedding\": -0.9965668320655823, \"dimension\": 6, \"position\": 76}, {\"embedding\": -0.9893633723258972, \"dimension\": 6, \"position\": 77}, {\"embedding\": -0.9782225489616394, \"dimension\": 6, \"position\": 78}, {\"embedding\": -0.963188648223877, \"dimension\": 6, \"position\": 79}, {\"embedding\": -0.9443213939666748, \"dimension\": 6, \"position\": 80}, {\"embedding\": -0.9216960668563843, \"dimension\": 6, \"position\": 81}, {\"embedding\": -0.8954026699066162, \"dimension\": 6, \"position\": 82}, {\"embedding\": -0.8655455708503723, \"dimension\": 6, \"position\": 83}, {\"embedding\": -0.8322440981864929, \"dimension\": 6, \"position\": 84}, {\"embedding\": -0.795630156993866, \"dimension\": 6, \"position\": 85}, {\"embedding\": -0.7558501362800598, \"dimension\": 6, \"position\": 86}, {\"embedding\": -0.7130619883537292, \"dimension\": 6, \"position\": 87}, {\"embedding\": -0.6674357056617737, \"dimension\": 6, \"position\": 88}, {\"embedding\": -0.6191535592079163, \"dimension\": 6, \"position\": 89}, {\"embedding\": -0.5684073567390442, \"dimension\": 6, \"position\": 90}, {\"embedding\": -0.5153986215591431, \"dimension\": 6, \"position\": 91}, {\"embedding\": -0.46033912897109985, \"dimension\": 6, \"position\": 92}, {\"embedding\": -0.40344759821891785, \"dimension\": 6, \"position\": 93}, {\"embedding\": -0.3449500501155853, \"dimension\": 6, \"position\": 94}, {\"embedding\": -0.28508007526397705, \"dimension\": 6, \"position\": 95}, {\"embedding\": -0.22407560050487518, \"dimension\": 6, \"position\": 96}, {\"embedding\": -0.1621788740158081, \"dimension\": 6, \"position\": 97}, {\"embedding\": -0.09963719546794891, \"dimension\": 6, \"position\": 98}, {\"embedding\": -0.03669850528240204, \"dimension\": 6, \"position\": 99}, {\"embedding\": 1.0, \"dimension\": 7, \"position\": 0}, {\"embedding\": 0.9980100989341736, \"dimension\": 7, \"position\": 1}, {\"embedding\": 0.9920483827590942, \"dimension\": 7, \"position\": 2}, {\"embedding\": 0.9821385741233826, \"dimension\": 7, \"position\": 3}, {\"embedding\": 0.9683201313018799, \"dimension\": 7, \"position\": 4}, {\"embedding\": 0.9506479501724243, \"dimension\": 7, \"position\": 5}, {\"embedding\": 0.9291924834251404, \"dimension\": 7, \"position\": 6}, {\"embedding\": 0.9040390253067017, \"dimension\": 7, \"position\": 7}, {\"embedding\": 0.8752877116203308, \"dimension\": 7, \"position\": 8}, {\"embedding\": 0.8430529236793518, \"dimension\": 7, \"position\": 9}, {\"embedding\": 0.8074630498886108, \"dimension\": 7, \"position\": 10}, {\"embedding\": 0.7686597108840942, \"dimension\": 7, \"position\": 11}, {\"embedding\": 0.7267972826957703, \"dimension\": 7, \"position\": 12}, {\"embedding\": 0.6820423603057861, \"dimension\": 7, \"position\": 13}, {\"embedding\": 0.6345730423927307, \"dimension\": 7, \"position\": 14}, {\"embedding\": 0.5845783352851868, \"dimension\": 7, \"position\": 15}, {\"embedding\": 0.532257080078125, \"dimension\": 7, \"position\": 16}, {\"embedding\": 0.47781768441200256, \"dimension\": 7, \"position\": 17}, {\"embedding\": 0.4214765727519989, \"dimension\": 7, \"position\": 18}, {\"embedding\": 0.36345821619033813, \"dimension\": 7, \"position\": 19}, {\"embedding\": 0.30399325489997864, \"dimension\": 7, \"position\": 20}, {\"embedding\": 0.243318572640419, \"dimension\": 7, \"position\": 21}, {\"embedding\": 0.18167544901371002, \"dimension\": 7, \"position\": 22}, {\"embedding\": 0.11930941045284271, \"dimension\": 7, \"position\": 23}, {\"embedding\": 0.056468550115823746, \"dimension\": 7, \"position\": 24}, {\"embedding\": -0.006597157102078199, \"dimension\": 7, \"position\": 25}, {\"embedding\": -0.06963648647069931, \"dimension\": 7, \"position\": 26}, {\"embedding\": -0.1323987990617752, \"dimension\": 7, \"position\": 27}, {\"embedding\": -0.1946340948343277, \"dimension\": 7, \"position\": 28}, {\"embedding\": -0.25609490275382996, \"dimension\": 7, \"position\": 29}, {\"embedding\": -0.31653639674186707, \"dimension\": 7, \"position\": 30}, {\"embedding\": -0.37571826577186584, \"dimension\": 7, \"position\": 31}, {\"embedding\": -0.43340474367141724, \"dimension\": 7, \"position\": 32}, {\"embedding\": -0.4893665015697479, \"dimension\": 7, \"position\": 33}, {\"embedding\": -0.5433804988861084, \"dimension\": 7, \"position\": 34}, {\"embedding\": -0.5952321887016296, \"dimension\": 7, \"position\": 35}, {\"embedding\": -0.6447150111198425, \"dimension\": 7, \"position\": 36}, {\"embedding\": -0.6916319727897644, \"dimension\": 7, \"position\": 37}, {\"embedding\": -0.7357962727546692, \"dimension\": 7, \"position\": 38}, {\"embedding\": -0.7770324349403381, \"dimension\": 7, \"position\": 39}, {\"embedding\": -0.8151761889457703, \"dimension\": 7, \"position\": 40}, {\"embedding\": -0.8500756621360779, \"dimension\": 7, \"position\": 41}, {\"embedding\": -0.8815921545028687, \"dimension\": 7, \"position\": 42}, {\"embedding\": -0.9096000790596008, \"dimension\": 7, \"position\": 43}, {\"embedding\": -0.933988094329834, \"dimension\": 7, \"position\": 44}, {\"embedding\": -0.9546589255332947, \"dimension\": 7, \"position\": 45}, {\"embedding\": -0.971530556678772, \"dimension\": 7, \"position\": 46}, {\"embedding\": -0.9845356941223145, \"dimension\": 7, \"position\": 47}, {\"embedding\": -0.9936226010322571, \"dimension\": 7, \"position\": 48}, {\"embedding\": -0.998755156993866, \"dimension\": 7, \"position\": 49}, {\"embedding\": -0.9999129772186279, \"dimension\": 7, \"position\": 50}, {\"embedding\": -0.9970912933349609, \"dimension\": 7, \"position\": 51}, {\"embedding\": -0.9903014898300171, \"dimension\": 7, \"position\": 52}, {\"embedding\": -0.9795705676078796, \"dimension\": 7, \"position\": 53}, {\"embedding\": -0.964941143989563, \"dimension\": 7, \"position\": 54}, {\"embedding\": -0.9464714527130127, \"dimension\": 7, \"position\": 55}, {\"embedding\": -0.9242351651191711, \"dimension\": 7, \"position\": 56}, {\"embedding\": -0.8983205556869507, \"dimension\": 7, \"position\": 57}, {\"embedding\": -0.8688308000564575, \"dimension\": 7, \"position\": 58}, {\"embedding\": -0.8358834981918335, \"dimension\": 7, \"position\": 59}, {\"embedding\": -0.7996094226837158, \"dimension\": 7, \"position\": 60}, {\"embedding\": -0.7601531147956848, \"dimension\": 7, \"position\": 61}, {\"embedding\": -0.7176715731620789, \"dimension\": 7, \"position\": 62}, {\"embedding\": -0.6723340749740601, \"dimension\": 7, \"position\": 63}, {\"embedding\": -0.6243206262588501, \"dimension\": 7, \"position\": 64}, {\"embedding\": -0.5738227963447571, \"dimension\": 7, \"position\": 65}, {\"embedding\": -0.5210408568382263, \"dimension\": 7, \"position\": 66}, {\"embedding\": -0.46618568897247314, \"dimension\": 7, \"position\": 67}, {\"embedding\": -0.4094752371311188, \"dimension\": 7, \"position\": 68}, {\"embedding\": -0.3511347472667694, \"dimension\": 7, \"position\": 69}, {\"embedding\": -0.2913972735404968, \"dimension\": 7, \"position\": 70}, {\"embedding\": -0.23049965500831604, \"dimension\": 7, \"position\": 71}, {\"embedding\": -0.1686851680278778, \"dimension\": 7, \"position\": 72}, {\"embedding\": -0.10619935393333435, \"dimension\": 7, \"position\": 73}, {\"embedding\": -0.04329042136669159, \"dimension\": 7, \"position\": 74}, {\"embedding\": 0.019790323451161385, \"dimension\": 7, \"position\": 75}, {\"embedding\": 0.08279230445623398, \"dimension\": 7, \"position\": 76}, {\"embedding\": 0.14546526968479156, \"dimension\": 7, \"position\": 77}, {\"embedding\": 0.20755885541439056, \"dimension\": 7, \"position\": 78}, {\"embedding\": 0.2688263952732086, \"dimension\": 7, \"position\": 79}, {\"embedding\": 0.3290245532989502, \"dimension\": 7, \"position\": 80}, {\"embedding\": 0.3879128098487854, \"dimension\": 7, \"position\": 81}, {\"embedding\": 0.4452572762966156, \"dimension\": 7, \"position\": 82}, {\"embedding\": 0.5008301138877869, \"dimension\": 7, \"position\": 83}, {\"embedding\": 0.5544094443321228, \"dimension\": 7, \"position\": 84}, {\"embedding\": 0.605782687664032, \"dimension\": 7, \"position\": 85}, {\"embedding\": 0.6547446846961975, \"dimension\": 7, \"position\": 86}, {\"embedding\": 0.7011010050773621, \"dimension\": 7, \"position\": 87}, {\"embedding\": 0.7446674108505249, \"dimension\": 7, \"position\": 88}, {\"embedding\": 0.7852699160575867, \"dimension\": 7, \"position\": 89}, {\"embedding\": 0.8227472901344299, \"dimension\": 7, \"position\": 90}, {\"embedding\": 0.856950581073761, \"dimension\": 7, \"position\": 91}, {\"embedding\": 0.8877431154251099, \"dimension\": 7, \"position\": 92}, {\"embedding\": 0.9150027632713318, \"dimension\": 7, \"position\": 93}, {\"embedding\": 0.9386210441589355, \"dimension\": 7, \"position\": 94}, {\"embedding\": 0.9585037231445312, \"dimension\": 7, \"position\": 95}, {\"embedding\": 0.9745717644691467, \"dimension\": 7, \"position\": 96}, {\"embedding\": 0.9867613911628723, \"dimension\": 7, \"position\": 97}, {\"embedding\": 0.9950238466262817, \"dimension\": 7, \"position\": 98}, {\"embedding\": 0.9993264079093933, \"dimension\": 7, \"position\": 99}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "RUN_EXAMPLES = True\n",
    "\n",
    "def show_example(fn,args=[]):\n",
    "    if __name__==\"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "def example_positional():\n",
    "    pe = PositionalEncoding(20, 0)\n",
    "    y = pe.forward(torch.zeros(1, 100, 20))\n",
    "\n",
    "    data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"embedding\": y[0, :, dim],\n",
    "                    \"dimension\": dim,\n",
    "                    \"position\": list(range(100)),\n",
    "                }\n",
    "            )\n",
    "            for dim in [4, 5, 6, 7]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(data)\n",
    "        .mark_line()\n",
    "        .properties(width=800)\n",
    "        .encode(x=\"position\", y=\"embedding\", color=\"dimension:N\")\n",
    "        .interactive()\n",
    "    )\n",
    "show_example(example_positional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c1412",
   "metadata": {},
   "source": [
    "Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d2f94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self,encoder,decoder,src_embed,tgt_embed,generator):\n",
    "        super(EncoderDecoder,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self,src,tgt,src_mask,tgt_mask):\n",
    "        return self.decode(self.encode(src,src_mask),src_mask,tgt,tgt_mask)\n",
    "    \n",
    "    def encode(self,src,src_mask):\n",
    "        return self.encoder(self.src_embed(src),src_mask)\n",
    "\n",
    "    def decode(self,memeory,src_mask,tgt,tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt),memeory,src_mask,tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e498c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model,vocab):\n",
    "        super(Generator,self).__init__()\n",
    "        self.proj = nn.Linear(d_model,vocab)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return log_softmax(self.proj(x),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9659c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "        src_vocab, tgt_vocab, N=6, d_model=512, d_ff = 2048, h =8, dropout=0.1\n",
    "):\n",
    "    \"Construct the model from hyperparameters\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model,dropout)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model,c(attn),c(ff),dropout),N),\n",
    "        Decoder(DecoderLayer(d_model,c(attn),c(attn),c(ff),dropout),N),\n",
    "        nn.Sequential(Embeddings(d_model,src_vocab),c(position)),\n",
    "        nn.Sequential(Embeddings(d_model,tgt_vocab),c(position)),\n",
    "        Generator(d_model,tgt_vocab)\n",
    "    )\n",
    "\n",
    "    # initialize parameters with glorot / fan_avg\n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47513125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3716813",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f01145e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Untrained Model Prediction: tensor([[0, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5, 5, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5, 5, 5, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5, 5, 5, 5, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5, 5, 5, 5, 5, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 5, 5, 5, 5, 5, 5, 5, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1, 7, 1]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1, 7, 1, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1, 7, 1, 7, 1]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1, 7, 1, 7, 1, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1, 7, 1, 7, 1, 7, 1]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 1, 7, 1, 7, 1, 7, 1, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 5, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 5, 3, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 5, 3, 5, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 5, 3, 5, 3, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 5, 3, 5, 3, 5, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 3, 5, 3, 5, 3, 5, 3, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0, 0, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0, 0, 0, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0, 0, 0, 0, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2, 2, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2, 2, 2, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2, 2, 2, 2, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2, 2, 2, 2, 2, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2, 2, 2, 2, 2, 2, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 7, 2, 2, 2, 2, 2, 2, 2, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8, 8, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8, 8, 8, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8, 8, 8, 8, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8, 8, 8, 8, 8, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 3, 8, 8, 8, 8, 8, 8, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2, 4, 9]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2, 4, 9, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2, 4, 9, 0, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2, 4, 9, 0, 5, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2, 4, 9, 0, 5, 2, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 2, 4, 9, 0, 5, 2, 4, 2]])\n",
      "Example Untrained Model Prediction: tensor([[0, 6]])\n",
      "Example Untrained Model Prediction: tensor([[0, 6, 3]])\n",
      "Example Untrained Model Prediction: tensor([[0, 6, 3, 8]])\n",
      "Example Untrained Model Prediction: tensor([[0, 6, 3, 8, 8]])\n",
      "Example Untrained Model Prediction: tensor([[ 0,  6,  3,  8,  8, 10]])\n",
      "Example Untrained Model Prediction: tensor([[ 0,  6,  3,  8,  8, 10, 10]])\n",
      "Example Untrained Model Prediction: tensor([[ 0,  6,  3,  8,  8, 10, 10, 10]])\n",
      "Example Untrained Model Prediction: tensor([[ 0,  6,  3,  8,  8, 10, 10, 10, 10]])\n",
      "Example Untrained Model Prediction: tensor([[ 0,  6,  3,  8,  8, 10, 10, 10, 10, 10]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4, 0]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4, 0, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4, 0, 5, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4, 0, 5, 4, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4, 0, 5, 4, 5, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4, 0, 5, 4, 5, 4, 5]])\n",
      "Example Untrained Model Prediction: tensor([[0, 5, 4, 0, 5, 4, 5, 4, 5, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4, 4, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4, 4, 4, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4, 4, 4, 7, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4, 4, 4, 7, 4, 7]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4, 4, 4, 7, 4, 7, 4]])\n",
      "Example Untrained Model Prediction: tensor([[0, 4, 4, 4, 4, 7, 4, 7, 4, 7]])\n"
     ]
    }
   ],
   "source": [
    "def inference_test():\n",
    "    test_model = make_model(11,11,2)\n",
    "    test_model.eval()\n",
    "    src = torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]])\n",
    "    src_mask = torch.ones(1,1,10)\n",
    "\n",
    "    memory = test_model.encode(src,src_mask)\n",
    "    ys = torch.zeros(1,1).type_as(src)\n",
    "\n",
    "    for i in range(9):\n",
    "        out = test_model.decode(\n",
    "            memory,src_mask,ys,subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        prob = test_model.generator(\n",
    "            out[:,-1]\n",
    "        )\n",
    "        _,next_word = torch.max(prob,dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.empty(1,1).type_as(src.data).fill_(next_word)],\n",
    "            dim=1\n",
    "        )\n",
    "        print(\"Example Untrained Model Prediction:\", ys)\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "    for _ in range(10):\n",
    "        inference_test()\n",
    "\n",
    "show_example(run_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb9863f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False,  True,  True,  True,  True,  True,  True,  True,  True,  True]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]])\n",
    "pad = 1\n",
    "src_mask = (src!=pad).unsqueeze(-2)\n",
    "src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f93b25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches and masking\n",
    "class Batch:\n",
    "\n",
    "    def __init__(self,src,tgt=None,pad=2): # 2 = <blank>\n",
    "\n",
    "        self.src = src\n",
    "        self.src_mask = (src!=pad).unsqueeze(-2)\n",
    "\n",
    "        if tgt is not None:\n",
    "            self.tgt = tgt[:,:-1]\n",
    "            self.tgt_y = tgt[:,1:]\n",
    "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
    "            self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt,pad):\n",
    "        \"create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146dd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3753b4ce",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83a5d09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainstep:\n",
    "\n",
    "    step: int= 0\n",
    "    accum_step : int = 0\n",
    "    samples: int = 0\n",
    "    tokens: int = 0\n",
    "\n",
    "def run_epoch(\n",
    "        data_iter,\n",
    "        model,\n",
    "        loss_compute,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        mode=\"train\",\n",
    "        accum_iter=1,\n",
    "        train_state=Trainstep()\n",
    "):\n",
    "    \"train a single epoch\"\n",
    "    start = time.time()\n",
    "    total_tokens=0\n",
    "    total_loss=0\n",
    "    tokens=0\n",
    "    n_accum=0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(\n",
    "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
    "        )\n",
    "        loss, loss_node = loss_compute(out, batch.tgt_y,batch.ntokens)\n",
    "\n",
    "        # loss_node = loss_node / accum_iter\n",
    "\n",
    "        if mode == \"train\" or mode == \"train+log\":\n",
    "            loss_node.backward()\n",
    "            train_state.step +=1\n",
    "            train_state.samples += batch.src.shape[0]\n",
    "            train_state.tokens += batch.ntokens\n",
    "            if i % accum_iter == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                n_accum += 1\n",
    "                train_state.accum_step += 1\n",
    "            scheduler.step()\n",
    "        total_loss+=loss\n",
    "        total_tokens+=batch.ntokens\n",
    "        tokens+= batch.ntokens\n",
    "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            elapsed = time.time() - start\n",
    "            print(\n",
    "                (\n",
    "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
    "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
    "                )\n",
    "                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n",
    "            )\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "        del loss\n",
    "        del loss_node\n",
    "    return total_loss / total_tokens, train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4858781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc3d9649",
   "metadata": {},
   "source": [
    "Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ba11869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "\n",
    "    def __init__(self,size,padding_idx,smoothing=0.0):\n",
    "        super(LabelSmoothing,self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0-smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self,x:torch.Tensor,target):\n",
    "        assert x.size(1)== self.size\n",
    "        true_dist = x.data.clone()\n",
    "\n",
    "        # fill every value with wrong idx smoothing \n",
    "        true_dist.fill_(self.smoothing / (self.size-2))\n",
    "        # now correct idx with smoothing\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1),self.confidence)\n",
    "        # Zero out the PAD token distribution\n",
    "        true_dist[:,self.padding_idx]=0\n",
    "        # If the target itself is PAD, zero out the entire row\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(),0.0)\n",
    "        self.true_dist = true_dist\n",
    "\n",
    "        return self.criterion(x, true_dist.clone().detach())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83d28f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-740ac4bb6a754174b75e9d2a5ba5bc5f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-740ac4bb6a754174b75e9d2a5ba5bc5f.vega-embed details,\n",
       "  #altair-viz-740ac4bb6a754174b75e9d2a5ba5bc5f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-740ac4bb6a754174b75e9d2a5ba5bc5f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-740ac4bb6a754174b75e9d2a5ba5bc5f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-740ac4bb6a754174b75e9d2a5ba5bc5f\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@6?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@6.1.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@7?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"6\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"6.1.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"7\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-462a8ac05baef651a79f7b45de1311d5\"}, \"mark\": {\"type\": \"rect\", \"color\": \"Blue\", \"opacity\": 1}, \"encoding\": {\"color\": {\"field\": \"target distribution\", \"scale\": {\"scheme\": \"viridis\"}, \"type\": \"quantitative\"}, \"x\": {\"field\": \"columns\", \"title\": null, \"type\": \"ordinal\"}, \"y\": {\"field\": \"rows\", \"title\": null, \"type\": \"ordinal\"}}, \"height\": 200, \"params\": [{\"name\": \"param_1e9efca18e7a2868\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"width\": 200, \"$schema\": \"https://vega.github.io/schema/vega-lite/v6.1.0.json\", \"datasets\": {\"data-462a8ac05baef651a79f7b45de1311d5\": [{\"target distribution\": 0.0, \"columns\": 0, \"rows\": 0}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 2}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 3}, {\"target distribution\": 0.0, \"columns\": 0, \"rows\": 4}, {\"target distribution\": 0.13333334028720856, \"columns\": 1, \"rows\": 0}, {\"target distribution\": 0.6000000238418579, \"columns\": 1, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 1, \"rows\": 2}, {\"target distribution\": 0.13333334028720856, \"columns\": 1, \"rows\": 3}, {\"target distribution\": 0.13333334028720856, \"columns\": 1, \"rows\": 4}, {\"target distribution\": 0.6000000238418579, \"columns\": 2, \"rows\": 0}, {\"target distribution\": 0.13333334028720856, \"columns\": 2, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 2, \"rows\": 2}, {\"target distribution\": 0.13333334028720856, \"columns\": 2, \"rows\": 3}, {\"target distribution\": 0.13333334028720856, \"columns\": 2, \"rows\": 4}, {\"target distribution\": 0.13333334028720856, \"columns\": 3, \"rows\": 0}, {\"target distribution\": 0.13333334028720856, \"columns\": 3, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 3, \"rows\": 2}, {\"target distribution\": 0.6000000238418579, \"columns\": 3, \"rows\": 3}, {\"target distribution\": 0.6000000238418579, \"columns\": 3, \"rows\": 4}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 0}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 1}, {\"target distribution\": 0.0, \"columns\": 4, \"rows\": 2}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 3}, {\"target distribution\": 0.13333334028720856, \"columns\": 4, \"rows\": 4}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_label_smoothing():\n",
    "    crit = LabelSmoothing(5, 0, 0.4)\n",
    "    predict = torch.FloatTensor(\n",
    "        [\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "            [0, 0.2, 0.7, 0.1, 0],\n",
    "        ]\n",
    "    )\n",
    "    crit(x=predict.log(), target=torch.LongTensor([2, 1, 0, 3, 3]))\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"target distribution\": crit.true_dist[x, y].flatten(),\n",
    "                    \"columns\": y,\n",
    "                    \"rows\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(5)\n",
    "            for x in range(5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect(color=\"Blue\", opacity=1)\n",
    "        .properties(height=200, width=200)\n",
    "        .encode(\n",
    "            alt.X(\"columns:O\", title=None),\n",
    "            alt.Y(\"rows:O\", title=None),\n",
    "            alt.Color(\n",
    "                \"target distribution:Q\", scale=alt.Scale(scheme=\"viridis\")\n",
    "            ),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_label_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da9250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "108c6e99",
   "metadata": {},
   "source": [
    "A First Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1447ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch_size, nbatches):\n",
    "    \"generate random data for a src-tgt copy task\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.randint(1,V, size=(batch_size,V))\n",
    "        data[:,0] = 1\n",
    "        src = data.requires_grad_(False).clone().detach()\n",
    "        tgt = data.requires_grad_(False).clone().detach()\n",
    "        yield Batch(src,tgt,pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c28027cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[True, True, True]],\n",
      "\n",
      "        [[True, True, True]]])\n",
      "tensor([[[ True, False],\n",
      "         [ True,  True]],\n",
      "\n",
      "        [[ True, False],\n",
      "         [ True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "vocab=3\n",
    "batch_size=2\n",
    "nbatches = 1\n",
    "data_iter = data_gen(vocab,batch_size,nbatches)\n",
    "for i,batch in enumerate(data_iter):\n",
    "    print(batch.src_mask)\n",
    "    print(batch.tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f2c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e740ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Computation\n",
    "class SimpleLossCompute:\n",
    "\n",
    "    def __init__(self,generator: Generator ,criterion):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def __call__(self,x,y,norm):\n",
    "        x = self.generator(x)\n",
    "        sloss = (\n",
    "            self.criterion(\n",
    "                x.contiguous().view(-1,x.size(-1)),\n",
    "                y.contiguous().view(-1)\n",
    "            )\n",
    "            /norm\n",
    "        )\n",
    "        return sloss.data * norm, sloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37dc3c",
   "metadata": {},
   "source": [
    "Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "def0c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model: EncoderDecoder,src,src_mask,max_len,start_symbol):\n",
    "    memory = model.encode(src,src_mask)\n",
    "    ys = torch.zeros(1,1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(\n",
    "            memory, src_mask, ys,\n",
    "            subsequent_mask(ys.size(1)).type_as(src.data)\n",
    "        )\n",
    "        prob = model.generator(out[:,-1])\n",
    "        _, next_word = torch.max(prob,dim=1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.zeros(1,1).type_as(src.data).fill_(next_word)],\n",
    "            dim=1\n",
    "        )\n",
    "        return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "041e36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    we have to default the step to 1 for LambdaLR function\n",
    "    to avoid zero raising to negative power.\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9cf0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e52a5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step:      1 | Accumulation Step:   2 | Loss:   3.25 | Tokens / Sec:  1321.5 | Learning Rate: 5.5e-06\n",
      "Epoch Step:      1 | Accumulation Step:   2 | Loss:   2.06 | Tokens / Sec:  1641.2 | Learning Rate: 6.1e-05\n",
      "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.74 | Tokens / Sec:  1656.7 | Learning Rate: 1.2e-04\n",
      "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.51 | Tokens / Sec:  1446.4 | Learning Rate: 1.7e-04\n",
      "Epoch Step:      1 | Accumulation Step:   2 | Loss:   1.07 | Tokens / Sec:  1492.0 | Learning Rate: 2.3e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m20\u001b[39m):\n\u001b[32m     15\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mSimpleLossCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     model.eval()\n\u001b[32m     25\u001b[39m     run_epoch(\n\u001b[32m     26\u001b[39m         data_gen(V,batch_size,\u001b[32m5\u001b[39m),\n\u001b[32m     27\u001b[39m         model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m         mode=\u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m     )[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(data_iter, model, loss_compute, optimizer, scheduler, mode, accum_iter, train_state)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# loss_node = loss_node / accum_iter\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mtrain+log\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43mloss_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     train_state.step +=\u001b[32m1\u001b[39m\n\u001b[32m     35\u001b[39m     train_state.samples += batch.src.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tekju\\Desktop\\nlp_scratch\\nlp_env\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    517\u001b[39m         Tensor.backward,\n\u001b[32m    518\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m         inputs=inputs,\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tekju\\Desktop\\nlp_scratch\\nlp_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    262\u001b[39m     retain_graph = create_graph\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tekju\\Desktop\\nlp_scratch\\nlp_env\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "V = 11\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "model = make_model(V,V, N=2)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=0.5, betas=(0.9,0.98), eps=1e-9\n",
    ")\n",
    "lr_scheduler = LambdaLR(\n",
    "    optimizer=optimizer,\n",
    "    lr_lambda= lambda step: rate(\n",
    "        step, model_size=model.src_embed[0].d_model, factor=1.0, warmup=400\n",
    "    )\n",
    ")\n",
    "batch_size = 80\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    run_epoch(\n",
    "        data_gen(V, batch_size,20),\n",
    "        model,\n",
    "        SimpleLossCompute(model.generator, criterion),\n",
    "        optimizer,\n",
    "        lr_scheduler,\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    model.eval()\n",
    "    run_epoch(\n",
    "        data_gen(V,batch_size,5),\n",
    "        model,\n",
    "        SimpleLossCompute(model.generator, criterion),\n",
    "        DummyOptimizer(),\n",
    "        DummyScheduler(),\n",
    "        mode=\"eval\"\n",
    "    )[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6db25d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
